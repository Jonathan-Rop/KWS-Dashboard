{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24d23155",
   "metadata": {},
   "source": [
    "Bronze Notebook is stage one of ingesting data before building the pipeline\n",
    "(a Kind of rough work of understadin the nature of data under examination)\n",
    "\n",
    "In this case;\n",
    "\n",
    "1. Import the data\n",
    "2. Understand what each row and coumn represent\n",
    "3. Identify rows and columns to be worked on after trancate\n",
    "4. Allign the data set answering workflow deliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27cb9e28",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m      2\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBronze\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Bronze\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4206ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r\"C:\\Users\\JKR\\Documents\\Project-csv\\jkr.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ac497c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, _c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e6dae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----+--------+----+------------+-----+----------+-----+-----------+---------+\n",
      "|                 _c0|                 _c1|  _c2| _c3|     _c4| _c5|         _c6|  _c7|       _c8|  _c9|       _c10|     _c11|\n",
      "+--------------------+--------------------+-----+----+--------+----+------------+-----+----------+-----+-----------+---------+\n",
      "|Watamu Marine Par...|                NULL| NULL|NULL|    NULL|NULL|        NULL| NULL|      NULL| NULL|       NULL|     NULL|\n",
      "|              Report|                NULL| NULL|NULL|    NULL|NULL|        NULL| NULL|      NULL| NULL|       NULL|     NULL|\n",
      "|                NULL|Total Expected Vi...| NULL|NULL|    NULL|NULL|        NULL| NULL|T/VISITORS|T/VEH|       NULL|     NULL|\n",
      "|                DATE|             CITIZEN| NULL|NULL|RESIDENT|NULL|NON-RESIDENT| NULL|      NULL| NULL|        KES|      USD|\n",
      "|                NULL|                   A|    C|   S|       A|   C|           A|    C|      NULL| NULL|       NULL|     NULL|\n",
      "|            1-Jul-25|               318.0|119.0|   0|    12.0|   2|       335.0| 49.0|     835.0| 70.0| 1714845.00| 704.3780|\n",
      "|            2-Jul-25|               329.0| 51.0|   0|    14.0| 5.0|       280.0| 62.0|     741.0| 98.0| 1573440.00|1061.1460|\n",
      "|            3-Jul-25|               431.0| 57.0|  86|     9.0| 5.0|       345.0| 79.0|    1012.0|119.0| 2059325.00|   963.00|\n",
      "|            4-Jul-25|               572.0| 76.0| 172|    10.0| 3.0|       427.0| 67.0|    1327.0|115.0| 2054360.00|2076.7400|\n",
      "|            5-Jul-25|               653.0| 83.0|   0|    30.0| 5.0|       468.0| 79.0|    1318.0|190.0| 2637555.00|  1550.00|\n",
      "|            6-Jul-25|               727.0|151.0|  40|    70.0| 9.0|       372.0| 86.0|    1455.0|222.0| 2396830.00|1581.2080|\n",
      "|            7-Jul-25|               335.0|111.0|   0|    11.0| 1.0|       252.0| 40.0|     750.0| 38.0|  889140.00|1584.0720|\n",
      "|            8-Jul-25|               163.0| 17.0|  70|      15| 6.0|       202.0| 31.0|     504.0| 38.0|  970500.00|        0|\n",
      "|              Totals|              3528.0|665.0| 368|   171.0|36.0|      2681.0|493.0|    7942.0|890.0|14295995.00|9520.5440|\n",
      "+--------------------+--------------------+-----+----+--------+----+------------+-----+----------+-----+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1707956c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
